[crawl]

# Logfile
logfile = log/crawl.f9beb4d9.log

# Network magic number
magic_number = f9beb4d9

# Default/fallback port number
port = 8333

# Redis database number
db = 0

# List of DNS seeders to get a subset of reachable nodes
seeders =
    seed.bitcoin.sipa.be
    dnsseed.bluematt.me
    dnsseed.bitcoin.dashjr.org
    seed.bitcoinstats.com
    seed.bitcoin.jonasschnelli.ch
    seed.btc.petertodd.org
    seed.bitcoin.sprovoost.nl
    dnsseed.emzy.de
    seed.bitcoin.wiz.biz
    seed.bitnodes.io

# Number of concurrent workers (greenlets)
workers = 700

# Print debug output
debug = False

# Public IP address for network interface
source_address = 0.0.0.0

# Protocol version to use for outgoing version message
protocol_version = 70016

# User agent (BIP 0014) to use for outgoing version message
# -----------------------------------------------------------------------------
#                                 NOTE TO USERS
# Please consider changing the user agent before running an instance of this
# crawler. This is so that users will not confuse your crawler with another
# instance that is already running and generating data for the project.
# -----------------------------------------------------------------------------
user_agent = /bitnodes.io:0.3/

# Services to use for outgoing network address message
services = 0

# Set to 1 to receive all txs
relay = 0

# Socket timeout
socket_timeout = 15

# Run cron tasks every given interval
cron_delay = 10

# Take full network snapshot at most at every given interval
snapshot_delay = 240

# Max. age for peering node to be included in crawl set
max_age = 28800

# Redis TTL for cached addr response (resultant TTL should be less than max_age)
addr_ttl = 7200

# Max. upper bound variance rate for addr_ttl (default: 2 to 6 hours TTL)
addr_ttl_var = 200

# Limit max. peers per node to be included in crawl set
peers_per_node = 500

# Attempt to establish connection with IPv6 nodes
ipv6 = True

# Limit max. nodes per IPv6 network prefix
ipv6_prefix = 64
nodes_per_ipv6_prefix = 1

# List of included ASNs
include_asns =

# List of included ASNs from external URL
include_asns_from_url =

# List of excluded ASNs
exclude_asns =

# List of excluded IPv4 networks
exclude_ipv4_networks =
    0.0.0.0/8
    10.0.0.0/8
    100.64.0.0/10
    127.0.0.0/8
    169.254.0.0/16
    172.16.0.0/12
    192.0.0.0/24
    192.0.0.0/29
    192.0.0.170/32
    192.0.0.171/32
    192.0.0.8/32
    192.0.2.0/24
    192.168.0.0/16
    192.175.48.0/24
    192.31.196.0/24
    192.52.193.0/24
    192.88.99.0/24
    198.18.0.0/15
    198.51.100.0/24
    203.0.113.0/24
    240.0.0.0/4
    255.255.255.255/32

# List of excluded IPv6 networks
exclude_ipv6_networks =

# Exclude IPv4 bogons
exclude_ipv4_bogons_from_urls =
    http://www.team-cymru.org/Services/Bogons/fullbogons-ipv4.txt
    http://www.spamhaus.org/drop/drop.txt
    https://www.spamhaus.org/drop/edrop.txt

# Exclude IPv6 bogons
exclude_ipv6_bogons_from_urls =

# List of excluded IPv4 networks from external URL
exclude_ipv4_networks_from_url =

# List of excluded IPv6 networks from external URL
exclude_ipv6_networks_from_url =

# Attempt to establish connection with .onion nodes
onion = True

# Tor proxy is required to connect to .onion address
tor_proxies =
    127.0.0.1:9050

# List of initial .onion nodes
onion_nodes =
    sgvi7z7ka6hajteud52trsj3y4yqeeuemeupc2sw5z6iabu2rmlfnkad.onion
    74ogmpum2ltbjb6eotr42nnq5wmwztdphtr5wcuoj2pqy2cnwor53nqd.onion
    cv4oeuszkf6llecp4wxcwdzlavtjene3ho6nc7gqr4jj5js3lgijrgid.onion
    bfbfmkt2k6hdctznsupgxdmavando7c6hfm5vwdampj6npea2trbtcqd.onion
    hscdnwo6xizoc5qmvikjaxyoj4k7bguam462gkmycrre2bbg6kn6cvid.onion
    g3zl23vpenyxwzufg7wpbbaku6w6gu2tgjd6f5nxr5xxnuny7773cuqd.onion
    txr3ob2hsweyago3wgqykfiyj52ywrwucdljvgk5qrbe4ehgh6rvwmad.onion
    zhea7pvhuzw4cte7pkd7u6lwjyiqczxi7wgvzhfovtjd7qwdc24pleqd.onion
    hoqlf3tpnq7bsowobivfpninp3eukhftv6kmtol4iworwwvnbdzh35yd.onion
    4jhkgrmzs32htjbbzuz4ia7xn34pwhqexyz2oi5ctzhjyjb46z3eo6yd.onion
    md3vskofydgnktvzdfwtntg7mubxb6ye3vmvzrlxkbf5teqrchufy6id.onion
    7plxio6wsmpwmws6ohvzu7v67vbp35jbgfg77kh4ylc3jlh52cqhopyd.onion
    4vf3hfnzgqqgh52p7lvupd3rpucehppnmsz4mrhdagi7zdmgnw25vpyd.onion
    vzleatncxglazfyw6f6keqi3276f2hewgisopidxh2mx3uxu4iflw2id.onion
    cd677pxnabnmemocs5u2dbuo2ikla2fikw3xse3wi6xseew7yp3ezgid.onion
    7wypdiaqh5h2zjw3uqec2tijjw2rnwsnuijeuq3xhyab3kdcy3lvsead.onion
    dekdeqqhqrh5fule7cfmmkvm6c7bydykm7al66eyamivwv2gkhbowaid.onion
    qtbxwqvxkx5npondl5i6uiyxkhv3t4x7kaouy23vcdv7svfwx4nt3zyd.onion
    fliynlju3prz2tstfthsb77culkluqolcysdxwfdwxl2hul5igeqagid.onion
    fju76rbuztarq7epipydyiip5vstyliadt5tty6avdwimct4uk6zyjyd.onion

# Include reachable nodes from https://bitnodes.io/#join-the-network
include_checked = False

# Relative path to directory containing timestamp-prefixed JSON crawl files
crawl_dir = data/crawl/f9beb4d9
